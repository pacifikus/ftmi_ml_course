### Задание 1 - 30 баллов

1. Сформулировать постановку задачу, которую хочется решать в рамках курса.

Критерии оценки:
  - Сформулирована бизнес-постановка задачи (например, реализовать спам/не спам детектор) - **3 балла**
  - Сформулирована постановка ML-задачи (бинарная классификация) - **2 балла**
  - Представлен набор данных, достаточный для решения поставленной задачи - **3 балла**

2. Выбрать и обосновать метрику для измерения качества.

В рамках данного пункта необходимо подобрать наиболее релевантную метрику или набор метрик для вашей задачи, написав краткое обоснование (1-2 предложения).

Критерии оценки:
- Предложена метрика - **3 балла**
- Присутствует корректное обоснование (включая связь с бизнес-целью/продуктовыми метриками, анализ стоимости ошибок и особенности данных, например, дисбаланс) - **5 баллов**

Дополнительный материал о выборе метрик и связи этого процесса с бизнес-постановкой задачи: https://habr.com/ru/company/jetinfosystems/blog/420261/

3. Провести EDA на своих данных

В рамках данного пункта необходимо провести предварительный разведочный анализ своего набора данных.

Критерии оценки:
- Рассмотрены базовые характеристики/статистики для набора данных - **3 балла**
- Реализованы наиболее релевантные визуализации - **5 баллов**
- По ходу работы присутствуют комментарии (вы, как эксперт в предметной области, можете проинтерпретировать полученные результаты анализа, визуализации, расcчитанные статистики, сделав выводы о том, каким образом лучше работать с набором данных в будущем, какие могут возникнуть проблемы, какую предобработку целесообразно сделать и тп). - **6 баллов**


## Сравнительная таблица метрик регрессии

| Метрика |Интерпретация | Когда использовать | Преимущества | Недостатки | Особенности |
|---------|---------------|-------------------|--------------|-----------|-------------|
| **MAE** (Средняя абсолютная ошибка) | Средняя абсолютная ошибка в исходных единицах | Данные с выбросами; интерпретируемость важна; сбалансированное отношение к ошибкам | Устойчива к выбросам; легко объяснить бизнесу; одинаковый вес для всех ошибок | Не штрафует большие ошибки; может скрывать систематические проблемы | Единицы: те же, что у целевой переменной (руб., км, часы) |
| **MSE** (Средняя квадратичная ошибка) | Средняя квадратичная ошибка | Критичны большие ошибки; оптимизация моделей; чувствительность нужна | Гладкая функция потерь; математически удобна для оптимизации; штрафует выбросы | Сложно интерпретировать; квадратичные единицы; высокочувствителена к выбросам | Единицы: квадрат целевой переменной; диапазон [0, ∞) |
| **RMSE** (Среднеквадратичное отклонение)  | Среднеквадратичное отклонение в исходных единицах | Баланс между MSE и MAE; интерпретируемость плюс чувствительность | Понятна бизнесу; штрафует большие ошибки; те же единицы, что MAE | Всё ещё чувствительна к выбросам; квадратный корень сложнее для оптимизации | Единицы: те же, что у целевой переменной; диапазон [0, ∞) |
| **MAPE** (Средняя процентная ошибка)  | Средняя процентная ошибка | Сравнение моделей на разных масштабах; когда ошибка зависит от масштаба | Масштабируется автоматически; хороша для сравнения; интуитивна (%) | **Не работает с нулевыми значениями** (деление на 0); асимметрична к пере/недопредсказаниям; может быть неограничена при малых y | Диапазон: [0, ∞) при наличии нулей в данных; асимметрична |
| **sMAPE** (Симметричная процентная ошибка) | Симметричная процентная ошибка | Разреженные данные (с нулями); когда пере/недопредсказания одинаково плохи; спрос/прогнозирование | Работает с нулями; симметрична; масштабируется; диапазон ограничен | Сложнее объяснить; нечувствительна к очень малым абсолютным ошибкам; две версии формулы (0-100% vs 0-200%) | Диапазон: [0, 1] или [0, 2] в зависимости от определения; симметрична |
| **R²** (Коэффициент детерминации)  | Доля объяснённой дисперсии | Оценка доли объяснённой вариации; сравнение моделей; качество подгонки | Нормализован [0,1]; сравним между моделями; интегральная метрика | Может быть отрицательным (плохая модель); может быть высоким даже при плохих предсказаниях; чувствителен к выбросам | Диапазон: (-∞, 1]; 0 = линия среднего; 1 = идеальная подгонка; может быть отрицательным |

## Сравнительная таблица метрик классификации

| Метрика | Интерпретация | Диапазон | Когда использовать | Преимущества | Недостатки | Особенности |
|---------|---------------|----------|-------------------|--------------|-----------|-------------|
| **Accuracy** (Точность) | Доля правильных предсказаний | [0, 1] | Сбалансированные данные; все классы одинаково важны | Интуитивна; просто считается; легко объяснить | **Вводит в заблуждение** при дисбалансе; не видит разницу между типами ошибок; модель может быть 95% точной, предсказав всё как класс большинства | ✗ Не рекомендуется как основная метрика при дисбалансе |
| **Precision** (Точность предсказаний) | Из предсказанных позитивов, сколько было правильных | [0, 1] | Когда FP дорого; спам-фильтры, fraud-детекция, модерация контента | Показывает надёжность положительных предсказаний; низкий FP-rate | Игнорирует FN (пропущенные случаи); может быть высокой при очень консервативной модели | «Из всех писем, отмеченных как спам, сколько действительно спам?» |
| **Recall** (Полнота)  | Из реальных позитивов, сколько модель нашла | [0, 1] | Когда FN дорого; медицина (диагностика), безопасность, обнаружение мошенничества | Показывает способность находить позитивы; низкий FN-rate | Игнорирует FP (ложные срабатывания); может быть высокой при очень либеральной модели | «Из всех больных людей, сколько модель правильно диагностировала?» |
| **F1-Score**  | Гармоническое среднее precision и recall | [0, 1] | Дисбалансированные данные; когда важны обе ошибки; **стандартная метрика** | Балансирует precision и recall; штрафует экстремумы; хороша для имбалансированных данных | Не настраивается; одинаков вес для precision и recall; не учитывает TN | Становится 0, если precision ИЛИ recall = 0 (строго) |
| **F-Beta Score** | Гибридная F-score с регулируемым весом | [0, 1] | Когда нужен баланс, но precision или recall важнее; β>1 → recall, β<1 → precision | Настраивается под задачу; лучше, чем F1 для асимметричных затрат | Нужно выбирать β; менее интерпретируема; может быть непонятна stakeholders | β=1 = F1; β=2 даёт recall вес ≈2x; β=0.5 даёт precision вес ≈2x |
| **ROC-AUC** | Способность модели разделить классы на всех порогах | [0, 1] | Сбалансированные данные; нужна оценка на всех порогах; кредиты, медицина | Инвариантна к порогу; показывает ранжирование; стандартная в индустрии | **Вводит в заблуждение при дисбалансе**; не учитывает precision; может быть 0.9 при 99% accuracy с нулевой precision | ROC-AUC=0.5 → random guessing; AUC=1 → perfect ranking |
| **MCC** (Matthews) |Корреляция между предсказаниями и реальностью | [-1, 1] | **Рекомендуется при дисбалансе** вместо ROC-AUC; бинарная классификация; реальные данные | Не зависит от дисбаланса; учитывает все 4 типа ошибок; высокий MCC = надёжная модель | Сложнее объяснить; -1 до +1 (нужен shift в мышлении); менее известна | MCC=0 → не лучше random; MCC=1 → perfect; MCC=-1 → opposite |


---
